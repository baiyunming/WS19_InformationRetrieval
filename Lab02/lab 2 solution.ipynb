{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Statistical Decision Making\n",
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the two-dimensional, discrete random variable $X = [X_1\\ X_2]^\\top$ subjected to the joint probability density $p_X$ as described in the following table.\n",
    "<div style=\"text-align: center\">$\\begin{array}{c|cc} p_X(X_1, X_2)  & X_2 = 0 & X_2 = 1 \\\\ \\hline\\hline X_1 = 0 & 0.4 & 0.3 \\\\ X_1 = 1 & 0.2 & 0.1\\end{array}$</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Compute the marginal probability densities $p_{X1}, p_{X2}$ and the conditional probability $P(X_2 = 0|X_1 = 0)$ as well as the expected value $\\mathbb{E}[X]$ and the covariance matrix $\\mathbb{E}[(X - \\mathbb{E}[X])(X - \\mathbb{E}[X])^\\top]$ by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 7 2 5 8 3 6 9]\n",
      "[0 2 3 1 2 4 1 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.arange(1,10).reshape(3,3)\n",
    "print(x.ravel('F'))\n",
    "print(x.ravel('F')//2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal probability: [p(x1=0), p(x1=1)] = [0.7 0.3]\n",
      "Marginal probability: [p(x2=0), p(x2=1)] = [0.6 0.4]\n",
      "p(x2=0 | x1=0) = 0.5714285714285715\n",
      "Expected value: [0.3 0.4]\n",
      "X_centered:\n",
      " [[-0.3  0.7 -0.3  0.7]\n",
      " [-0.4 -0.4  0.6  0.6]]\n",
      "Covariance matrix:\n",
      " [[ 0.21 -0.02]\n",
      " [-0.02  0.24]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# joint probability table\n",
    "p_table = np.array([[0.4, 0.3], [0.2, 0.1]])\n",
    "\n",
    "# each column of X contains a possible event. 1st row corresponds to x1,\n",
    "# 2nd row corresponds to x2\n",
    "#X = [[0 1 0 1],\n",
    "#     [0 0 1 1]]\n",
    "X = np.array([[0, 1, 0, 1], \n",
    "              [0, 0, 1, 1]])\n",
    "\n",
    "# p_table.ravel('F') = [0.4  0.2  0.3  0.1] are the joint probability values that\n",
    "# correspond to these columns\n",
    "\n",
    "# marginal probabilities: sum accross rows\n",
    "p_x1 = np.sum(p_table, axis=1)\n",
    "p_x2 = np.sum(p_table, axis=0)\n",
    "\n",
    "print('Marginal probability: [p(x1=0), p(x1=1)] = {}'.format(p_x1))\n",
    "print('Marginal probability: [p(x2=0), p(x2=1)] = {}'.format(p_x2))\n",
    "\n",
    "# conditional  p(x2 = 0 | x1 = 0)\n",
    "# p(A|B) = p(A \\intersect B) / p(B)\n",
    "p_x2equals0condx1equals0 = p_table[0,0] / p_x1[0]\n",
    "print('p(x2=0 | x1=0) = {}'.format(p_x2equals0condx1equals0))\n",
    "\n",
    "# expected value\n",
    "E_X = np.dot(X, p_table.ravel('F')) # ravel('F') while keeping column order\n",
    "print('Expected value: {}'.format(E_X))\n",
    "\n",
    "# covariance matrix\n",
    "X_centered = X - np.expand_dims(E_X, axis=1) # expand_dims is needed so that numpy is able to subtract the vector from the matrix\n",
    "print(\"X_centered:\\n {}\".format(X_centered))\n",
    "CovX = np.dot(np.dot(X_centered, np.diag(p_table.ravel('F'))), X_centered.T)\n",
    "print('Covariance matrix:\\n {}'.format(CovX))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Write a PYTHON function `toyrnd` that expects the positive integer parameter `n` as its input and returns a matrix `X` of size `[2,n]`, containing `n` samples drawn independently from the distribution $p_X$, as its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toyrnd(n):\n",
    "    X_out = np.zeros((2,n))\n",
    "    Q = np.zeros((n,))\n",
    "    T = np.random.rand(n)\n",
    "     \n",
    "    # Interpreting [x1, x2] as binary number and Q as its decimal representation\n",
    "    Q[T>0.4] = 1\n",
    "    Q[T>0.7] = 2\n",
    "    Q[T>0.9] = 3\n",
    "    \n",
    "    X_out[0] = Q // 2 # floor division\n",
    "    X_out[1] = Q % 2 # modulus division\n",
    "    \n",
    "    return X_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Verify your results in a) by generating `10000` samples with `toyrnd` and computing the respective empirical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical marginal probability: [p(x1=0), p(x1=1)] = [0.69998606 0.30001394]\n",
      "Empirical marginal probability: [p(x2=0), p(x2=1)] = [0.59998857 0.40001143]\n",
      "Empirical conditional probability P(x2=0|x1=0): 0.5714309224957994\n",
      "Empirical expected value: [0.30001394 0.40001143]\n",
      "Empirical covariance matrix:\n",
      " [[ 0.21000558 -0.01998996]\n",
      " [-0.01998996  0.24000229]]\n"
     ]
    }
   ],
   "source": [
    "N = 100000000\n",
    "X_observed = toyrnd(N)\n",
    "# marginal probabilities\n",
    "p_X1equals0_empirical = np.float(np.sum(X_observed[0,:]==0))/N\n",
    "p_X1equals1_empirical = np.float(np.sum(X_observed[0,:]==1))/N\n",
    "p_X2equals0_empirical = np.float(np.sum(X_observed[1,:]==0))/N\n",
    "p_X2equals1_empirical = np.float(np.sum(X_observed[1,:]==1))/N\n",
    "\n",
    "p_x1_empirical = np.array([p_X1equals0_empirical, p_X1equals1_empirical])\n",
    "p_x2_empirical = np.array([p_X2equals0_empirical, p_X2equals1_empirical])\n",
    "\n",
    "print('Empirical marginal probability: [p(x1=0), p(x1=1)] = {}'.format(p_x1_empirical))\n",
    "print('Empirical marginal probability: [p(x2=0), p(x2=1)] = {}'.format(p_x2_empirical))\n",
    "\n",
    "# conditional probability\n",
    "X2condX1equals0 = X_observed[1, X_observed[0,:]==0]\n",
    "P_X2equals0condX1eqzals0_empirical = np.float(np.sum(X2condX1equals0 == 0)) / len(X2condX1equals0)\n",
    "print('Empirical conditional probability P(x2=0|x1=0):', P_X2equals0condX1eqzals0_empirical)\n",
    "# expected value\n",
    "E_X_empirical = np.sum(X_observed, axis=1)/N\n",
    "print('Empirical expected value: {}'.format(E_X_empirical))\n",
    "\n",
    "# covariance matrix\n",
    "CovX_empirical = np.dot(X_observed - np.expand_dims(E_X_empirical, axis=1), (X_observed - np.expand_dims(E_X_empirical, axis=1)).T) / N\n",
    "print('Empirical covariance matrix:\\n {}'.format(CovX_empirical))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "The MNIST training set consists of handwritten digits from 0 to 9, stored as PNG files of size $28 \\times 28$ and indexed by label. Download the provided ZIP file from Moodle and make yourself familiar with the directory structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Grayscale images are typically described as matrices of `uint8` values. For numerical calculations, it is more sensible to work with floating point numbers. Load two (abitrary) images from the database and convert them to matrices `I1` and `I2` of `float64` values in the interval $[0, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First image min/max value: 0.0/255.0\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "# define to image paths which to import\n",
    "data_folder = './mnist/'\n",
    "\n",
    "impath1 = data_folder + 'd2/d2_0075.png'\n",
    "impath2 = data_folder + 'd3/d3_0013.png'\n",
    "\n",
    "# import and convert to numpy array\n",
    "I1 = np.array(imageio.imread(impath1)).astype(np.float64)\n",
    "I2 = np.array(imageio.imread(impath2)).astype(np.float64)\n",
    "\n",
    "# check values\n",
    "print('First image min/max value: {}/{}'.format(np.min(I1), np.max(I1)))\n",
    "\n",
    "# normalize values to [0,1]\n",
    "I1 = I1 / 255.\n",
    "I2 = I2 / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(I1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) The matrix equivalent of the euclidean norm $\\|\\cdot\\|_2$ is the Frobenius norm. For any matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, it is defined as\n",
    "\t\t\t\\begin{equation}\n",
    "\t\t\t    \\|\\mathbf{A}\\|_F = \\sqrt{\\mathrm{tr}(\\mathbf{A}^\\top \\mathbf{A})},\n",
    "\t\t\t\\end{equation}\n",
    "\t\t\twhere $\\mathrm{tr}$ denotes the trace of a matrix. Compute the distance $\\|\\mathbf{I}_1 - \\mathbf{I}_2\\|_F$ between the images `I1` and `I2` by using three different procedures in PYTHON:\t\t\t\n",
    "-  Running the `numpy.linalg.norm` function with the `'fro'` parameter\n",
    "-  Directly applying the above equation\n",
    "-  Computing the euclidean norm between the vectorized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Frobenius norm: 11.715896790298329\n",
      "Implemented Frobenius norm: 11.715896790298329\n",
      "Euclidean norm of vectorized images: 11.715896790298329\n"
     ]
    }
   ],
   "source": [
    "# using frobenius nor\n",
    "%timeit\n",
    "frob1 = np.linalg.norm(I1 -I2 , 'fro')\n",
    "\n",
    "print('Numpy Frobenius norm: {}'.format(frob1))\n",
    "\n",
    "# using formula\n",
    "frob2 = np.sqrt(np.trace(np.matmul((I1 - I2), (I1 - I2).T)))\n",
    "\n",
    "print('Implemented Frobenius norm: {}'.format(frob2))\n",
    "# using euclidean norm of vectorized images\n",
    "frob3 = np.sqrt(np.dot((I1 - I2).ravel(), (I1 - I2).ravel()))\n",
    "print('Euclidean norm of vectorized images: {}'.format(frob3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) In the following, we want to solve a simple classification problem by applying *$k$-Nearest Neighbours*. To this end, choose two digit classes, e.g. $0$ and $1$, and load `n_train = 500` images from each class to the workspace. Convert them according to subtask a) and store them in vectorized form in the matrix `X_train` of size `[784, 2*n_train]`. Provide an indicator vector `Y_train` of length `2*n_train` that assigns the respective digit class label to each column of `X_train`.\n",
    "\n",
    "From each of the two classes, choose another set of `n_test=10` images and create the according matrices `X_test` and `Y_test`. Now, for each sample in the test set, determine the `k = 20` training samples with the smallest Frobenius distance to it and store their indices in the `2*n_test, k` matrix `NN`. Generate a vector `Y_kNN` containing the respective estimated class labels by performing a majority vote on `NN`. Compare the result with `Y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Loading test data...\n",
      "Computing Frobenius distances...\n",
      "Determining nearest neighbors...\n",
      "[[224 249 234 450 402  94  36  98 451 310 433  93  76 414  41  32 259 230\n",
      "   28 203]\n",
      " [377 418 435 365 341 245 366 312 156 456 371 398 464  53 171 452  73 324\n",
      "  427 229]\n",
      " [347 140 175   5 638 446 337 272 177 242 299 468 439 746 343 879 800 809\n",
      "  390 575]\n",
      " [380 187  78 142 361 165 320 432 307 338 707 335 414 254 251 169  41 334\n",
      "  419 433]\n",
      " [141 155 250 146 151 243 327 138 147 150 372 887  94 105 235  95 732  51\n",
      "  227 266]\n",
      " [137 266 249 327  28  76 250 310 360  70  52 138 257 243 110 235 402 450\n",
      "  422 146]\n",
      " [103 440 197 430 629  15 415 465 189 751 626 265 959 382 143 348 125 897\n",
      "  496 695]\n",
      " [ 98 249 137 310 402  36  76  95 224 360  94 138  39  32  52  41 250 230\n",
      "  227 235]\n",
      " [382 447  96  75 385  66 395 407 331  40 322 196  48 707  62 819 311 492\n",
      "  280 695]\n",
      " [287 156 172 139 365 444 829 418 481 328 312 371 341 366 843 178 377 174\n",
      "  362 322]\n",
      " [991 814 665 847 543 899 919 579 866 995 967 574 810 670 734 566 671 682\n",
      "  818 800]\n",
      " [656 505 690 978 649 625 926 705 736 876 515 706 696 979 863 904 524 768\n",
      "  945 787]\n",
      " [944 654 721 548 832 893 528 853 606 951 754 663 755 781 715 757 851 779\n",
      "  949 862]\n",
      " [500 993 803 633 539 546 860 530 932 997 869 807 925 724 792 794 723 759\n",
      "  660 506]\n",
      " [613 805 947 721 604 649 862 647 809 930 672 667 799 860 516 917 569 513\n",
      "  723 902]\n",
      " [998  55 517 747 910 537 514 554  47  24 729  50 529 511  93 535 740 727\n",
      "  532 737]\n",
      " [997 518 982 884 759 687 988 784 902 503 500 646 672 660 516 750 231 880\n",
      "  973 872]\n",
      " [967 671 566 827 670 669 534 543 995 525 762 819 846 529 574 888 818 994\n",
      "  652 568]\n",
      " [841 806 828 904 881 557 725 609 583 573 577 722 800 821 812 764 635 627\n",
      "  505 968]\n",
      " [689 544 681  25 951 921 615 591 954 895 507 588 686 755 906 898 592 955\n",
      "  697 407]]\n",
      "Ground truth label data:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0.   0.   0.3  0.05 0.1  0.   0.3  0.   0.15 0.1  1.   1.   1.   1.\n",
      " 1.   0.75 0.95 1.   1.   0.9 ]\n",
      "Labels determined by kNN:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# chose which numbers to load:\n",
    "d_id1 = 2\n",
    "d_id2 = 3\n",
    "d = [d_id1, d_id2]\n",
    "\n",
    "# define # of training and testing samples\n",
    "n_train = 500\n",
    "n_test = 10\n",
    "k = 20\n",
    "\n",
    "# initialize data matrices\n",
    "X_train = np.zeros((784, 2*n_train))\n",
    "X_test = np.zeros((784, 2*n_test))\n",
    "\n",
    "print('Loading training data...')\n",
    "for j in range(0,n_train):\n",
    "    impath = data_folder + 'd' + str(d[0]) + '/d' + str(d[0]) + '_' + str(j+1).zfill(4) + '.png'\n",
    "    X_train[:,0*n_train+j] = np.array(imageio.imread(impath)).astype(np.float).ravel()/255\n",
    "    impath = data_folder + 'd' + str(d[1]) + '/d' + str(d[1]) + '_' + str(j+1).zfill(4) + '.png'\n",
    "    X_train[:,1*n_train+j] = np.array(imageio.imread(impath)).astype(np.float).ravel()/255\n",
    "        \n",
    "Y_train = np.concatenate((np.zeros(n_train), np.ones(n_train)))\n",
    "print(X_train)\n",
    "\n",
    "print('Loading test data...')\n",
    "for j in range(n_test):\n",
    "    impath = data_folder + 'd' + str(d[0]) + '/d' + str(d[0]) + '_' + str(n_train+j+1).zfill(4) + '.png'\n",
    "    X_test[:,0*n_test+j] = np.array(imageio.imread(impath)).astype(np.float).ravel()/255\n",
    "    impath = data_folder + 'd' + str(d[1]) + '/d' + str(d[1]) + '_' + str(n_train+j+1).zfill(4) + '.png'\n",
    "    X_test[:,1*n_test+j] = np.array(imageio.imread(impath)).astype(np.float).ravel()/255\n",
    "    \n",
    "Y_test = np.concatenate((np.zeros(n_test), np.ones(n_test)))\n",
    "\n",
    "print('Computing Frobenius distances...')\n",
    "\n",
    "D = np.zeros((2*n_test, 2*n_train))\n",
    "for i in range(2*n_test):\n",
    "    # compute norm of distance of test sample i to all training samples\n",
    "    D[i,:] = np.sqrt(np.sum((np.expand_dims(X_test[:,i], axis=1) - X_train) ** 2, axis=0))\n",
    "    \n",
    "print('Determining nearest neighbors...')\n",
    "# np.argsort outputs indices required for sorting\n",
    "NN = np.argsort(D, axis = 1)\n",
    "# we only need the k closest neighbors, hence, we cut off after k columns\n",
    "NN = NN[:,0:k]\n",
    "print(NN)\n",
    "print('Ground truth label data:')\n",
    "print(Y_test.astype(np.float))\n",
    "\n",
    "# compute nearest neighbor labelling\n",
    "# sum over labels of k nearest training examples\n",
    "# and divide by k\n",
    "# if the resulting number is smaller than 0.5, we assign label 0\n",
    "# if the resulting number is greater, we assign label 1\n",
    "print(np.sum(Y_train[NN], axis=1)/k)\n",
    "kNN_mask = np.sum(Y_train[NN], axis=1)/k >= 0.5\n",
    "Y_kNN= kNN_mask.astype(np.float)\n",
    "print('Labels determined by kNN:')\n",
    "print(Y_kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
